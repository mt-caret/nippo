---
title: log 2019-12-05
---

## The Laplace Approximation

Yesterday during the PRML reading group, this topic came up and I was a bit
confused, so today I want to write a bit about this.

The concept of the laplace approximation itself is pretty simple:
you can approximate some unimodal probability distribution $p(x)$ with a Gaussian,
given you can find the mode $x_0$.

First, let $f(x) = \log p(x)$ so $p(x) = \exp{(h(x))}$. Taking a taylor series
approximation of $f(x)$ around $x_0$ gives the following:

$$
\begin{aligned}
f(x)
&\approx h(x_0) + h'(x_0) (x - x_0) + \frac{1}{2}h''(x_0) (x - x_0)^2 \\
&\approx h(x_0) + \frac{1}{2}h''(x_0) (x - x_0)^2
\end{aligned}
$$

As $x_0$ is a mode, $h'(x_0) = 0$ and the corresponding
term disappears. Going back to $p(x)$, this starts to look like a Gaussian.

$$
\begin{aligned}
p(x) &= \exp{(h(x))} \\
&\approx \exp{(h(x_0) + \frac{1}{2}h''(x_0) (x - x_0)^2)} \\
&\approx \exp{(h(x_0))} \sqrt{\frac{2\pi}{- h''(x_0)}} \mathcal{N}(x_0; -h''(x_0)^{-1})
\end{aligned}
$$

I was going to write a bit more on this topic, but unfortunately I'm seriously
busy right now, so I'm going to leave further elaboration for another day.
Here are a number of resources to refer back to later;

- [Laplace approximation](https://ufal.mff.cuni.cz/~jurcicek/NPFL108-BI-2014LS/04-approximate-inference-laplace-approximation.pdf)
- [Advanced Statistical Computing](https://bookdown.org/rdpeng/advstatcomp/laplace-approximation.html#computing-the-posterior-mean)
- [Bayesian model comparison - Metacademy](https://metacademy.org/graphs/concepts/laplace_approximation#focus=bayesian_model_comparison&mode=learn)

